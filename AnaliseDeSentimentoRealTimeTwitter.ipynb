{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Data Science Academy</font>\n",
    "# <font color='blue'>Big Data Real-Time Analytics com Python e Spark</font>\n",
    "\n",
    "# <font color='blue'>Capítulo 10</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *********** Atenção: *********** \n",
    "Utilize Java JDK 1.8 ou 11 e Apache Spark 2.4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****** Caso receba mensagem de erro \"name 'sc' is not defined\", interrompa o pyspark e apague o diretório metastore_db no mesmo diretório onde está este Jupyter notebook ******"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acesse http://localhost:4040 sempre que quiser acompanhar a execução dos jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Streaming - Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vamos por meio desse projeto ler em tempo real os tweets feitos em nossa conta do twitter e aplicar em tempo real um método de classificação de machine learning ( Naive Bayes ), para classificar se o Tweet feito corresponde a um sentimento Positivo ou Negativo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Importando as ferramentas que usaremos e Criando as Sessões necessárias no Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pode ser necessário instalar esses pacotes\n",
    "#!pip install requests_oauthlib\n",
    "#!pip install twython\n",
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Módulos usados\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark import SparkContext\n",
    "#Autenticação de sessão para poder acessar o twitter\n",
    "from requests_oauthlib import OAuth1Session\n",
    "from operator import add\n",
    "import requests_oauthlib\n",
    "from time import gmtime, strftime\n",
    "import requests\n",
    "import time\n",
    "import string\n",
    "import ast\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pacote NLTK\n",
    "import nltk\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.corpus import subjectivity\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequência de update\n",
    "INTERVALO_BATCH = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o StreamingContext\n",
    "ssc = StreamingContext(sc, INTERVALO_BATCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Treinando o Classificador de Análise de Sentimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vamos utilizar o seguinte dataset para treinar o nosso modelo de classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma parte essencial da criação de um algoritmo de análise de sentimento (ou qualquer algoritmo de mineração de dados) é ter um conjunto de dados abrangente ou \"Corpus\" para o aprendizado, bem como um conjunto de dados de teste para garantir que a precisão do seu algoritmo atende aos padrões que você espera. Isso também permitirá que você ajuste o seu algoritmo a fim de deduzir melhores (ou mais precisas) características de linguagem natural que você poderia extrair do texto e que vão contribuir para a classificação de sentimento, em vez de usar uma abordagem genérica. Tomaremos como base o dataset de treino fornecido pela Universidade de Michigan, para competições do Kaggle --> https://inclass.kaggle.com/c/si650winter11."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse dataset contém 1,578,627 tweets classificados e cada linha é marcada como: \n",
    "\n",
    "### 1 para o sentimento positivo \n",
    "### 0 para o sentimento negativo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo o arquivo texto e criando um RDD em memória com Spark\n",
    "arquivo = sc.textFile(\"dataset/dataset_analise_sentimento.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(arquivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ItemID,Sentiment,SentimentSource,SentimentText',\n",
       " '1,0,Sentiment140,                     is so sad for my APL friend.............',\n",
       " '2,0,Sentiment140,                   I missed the New Moon trailer...',\n",
       " '3,1,Sentiment140,              omg its already 7:30 :O',\n",
       " \"4,0,Sentiment140,          .. Omgaga. Im sooo  im gunna CRy. I've been at this dentist since 11.. I was suposed 2 just get a crown put on (30mins)...\",\n",
       " '5,0,Sentiment140,         i think mi bf is cheating on me!!!       T_T',\n",
       " '6,0,Sentiment140,         or i just worry too much?        ',\n",
       " '7,1,Sentiment140,       Juuuuuuuuuuuuuuuuussssst Chillin!!',\n",
       " '8,0,Sentiment140,       Sunny Again        Work Tomorrow  :-|       TV Tonight',\n",
       " '9,1,Sentiment140,      handed in my uniform today . i miss you already']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arquivo.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Podemos observar que cada avaliação está separada por uma virgula e que no RDD  possui cabeçalho\n",
    "Podemos também observar que a classificação de cada frase está na posição 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo o cabeçalho\n",
    "\n",
    "# Informando que o cabeçalho está na primeira posição do RDD\n",
    "header = arquivo.take(1)[0]\n",
    "#Salvando o novo dataset Sem o cabeçalho \n",
    "dataset = arquivo.filter(lambda line: line != header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.PipelinedRDD"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essa função vai fazer o primerio pré processamento dados da RDD\n",
    "\n",
    "#1°- Ele mapeia cada uma das linhas, ou seja, cada uma das avaliações, e divide elas em colunas,\n",
    "# assim estamos dividindo as frases em palavras\n",
    "\n",
    "# 2° Cria uma tupla de valores em que o primeiro é exatamente um array de palavras das frases e o segundo\n",
    "# valor é a classificação dessa frase se ela é classe 1 ( positiva) ou classe 0 (negativa)\n",
    "\n",
    "# 3° Por fim como estamos trabalhando com frases em um algoritmo de classificação temos uma importante etapa\n",
    "# dessa função que é retirar todo tipo de pontuação das frases e substituir por espaços em Branco \n",
    "def get_row(line):\n",
    "  row = line.split(',')\n",
    "  sentimento = row[1]\n",
    "  tweet = row[3].strip()\n",
    "  translator = str.maketrans({key: None for key in string.punctuation})\n",
    "  tweet = tweet.translate(translator)\n",
    "  tweet = tweet.split(' ')\n",
    "  tweet_lower = []\n",
    "  for word in tweet:\n",
    "    tweet_lower.append(word.lower())\n",
    "  return (tweet_lower, sentimento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica a função a cada linha do dataset\n",
    "dataset_treino = dataset.map(lambda line: get_row(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['is', 'so', 'sad', 'for', 'my', 'apl', 'friend'], '0'),\n",
       " (['i', 'missed', 'the', 'new', 'moon', 'trailer'], '0'),\n",
       " (['omg', 'its', 'already', '730', 'o'], '1'),\n",
       " (['',\n",
       "   'omgaga',\n",
       "   'im',\n",
       "   'sooo',\n",
       "   '',\n",
       "   'im',\n",
       "   'gunna',\n",
       "   'cry',\n",
       "   'ive',\n",
       "   'been',\n",
       "   'at',\n",
       "   'this',\n",
       "   'dentist',\n",
       "   'since',\n",
       "   '11',\n",
       "   'i',\n",
       "   'was',\n",
       "   'suposed',\n",
       "   '2',\n",
       "   'just',\n",
       "   'get',\n",
       "   'a',\n",
       "   'crown',\n",
       "   'put',\n",
       "   'on',\n",
       "   '30mins'],\n",
       "  '0'),\n",
       " (['i',\n",
       "   'think',\n",
       "   'mi',\n",
       "   'bf',\n",
       "   'is',\n",
       "   'cheating',\n",
       "   'on',\n",
       "   'me',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   'tt'],\n",
       "  '0'),\n",
       " (['or', 'i', 'just', 'worry', 'too', 'much'], '0'),\n",
       " (['juuuuuuuuuuuuuuuuussssst', 'chillin'], '1'),\n",
       " (['sunny',\n",
       "   'again',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   'work',\n",
       "   'tomorrow',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   'tv',\n",
       "   'tonight'],\n",
       "  '0'),\n",
       " (['handed',\n",
       "   'in',\n",
       "   'my',\n",
       "   'uniform',\n",
       "   'today',\n",
       "   '',\n",
       "   'i',\n",
       "   'miss',\n",
       "   'you',\n",
       "   'already'],\n",
       "  '1'),\n",
       " (['hmmmm', 'i', 'wonder', 'how', 'she', 'my', 'number', ''], '1'),\n",
       " (['i', 'must', 'think', 'about', 'positive'], '0'),\n",
       " (['thanks',\n",
       "   'to',\n",
       "   'all',\n",
       "   'the',\n",
       "   'haters',\n",
       "   'up',\n",
       "   'in',\n",
       "   'my',\n",
       "   'face',\n",
       "   'all',\n",
       "   'day',\n",
       "   '112102'],\n",
       "  '1'),\n",
       " (['this', 'weekend', 'has', 'sucked', 'so', 'far'], '0'),\n",
       " (['jb', 'isnt', 'showing', 'in', 'australia', 'any', 'more'], '0'),\n",
       " (['ok', 'thats', 'it', 'you', 'win'], '0'),\n",
       " (['lt', 'this', 'is', 'the', 'way', 'i', 'feel', 'right', 'now'], '0'),\n",
       " (['',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   'awhhe',\n",
       "   'man',\n",
       "   'im',\n",
       "   'completely',\n",
       "   'useless',\n",
       "   'rt',\n",
       "   'now',\n",
       "   'funny'],\n",
       "  '0'),\n",
       " (['feeling',\n",
       "   'strangely',\n",
       "   'fine',\n",
       "   'now',\n",
       "   'im',\n",
       "   'gonna',\n",
       "   'go',\n",
       "   'listen',\n",
       "   'to',\n",
       "   'some',\n",
       "   'semisonic',\n",
       "   'to',\n",
       "   'celebrate'],\n",
       "  '1'),\n",
       " (['huge', 'roll', 'of', 'thunder', 'just', 'nowso', 'scary'], '0'),\n",
       " (['i',\n",
       "   'just',\n",
       "   'cut',\n",
       "   'my',\n",
       "   'beard',\n",
       "   'off',\n",
       "   'its',\n",
       "   'only',\n",
       "   'been',\n",
       "   'growing',\n",
       "   'for',\n",
       "   'well',\n",
       "   'over',\n",
       "   'a',\n",
       "   'year',\n",
       "   'im',\n",
       "   'gonna',\n",
       "   'start',\n",
       "   'it',\n",
       "   'over',\n",
       "   'shaunamanu',\n",
       "   'is',\n",
       "   'happy',\n",
       "   'in',\n",
       "   'the',\n",
       "   'meantime'],\n",
       "  '0'),\n",
       " (['very', 'sad', 'about', 'iran'], '0'),\n",
       " (['wompppp', 'wompp'], '0'),\n",
       " (['youre',\n",
       "   'the',\n",
       "   'only',\n",
       "   'one',\n",
       "   'who',\n",
       "   'can',\n",
       "   'see',\n",
       "   'this',\n",
       "   'cause',\n",
       "   'no',\n",
       "   'one',\n",
       "   'else',\n",
       "   'is',\n",
       "   'following',\n",
       "   'me',\n",
       "   'this',\n",
       "   'is',\n",
       "   'for',\n",
       "   'you',\n",
       "   'because',\n",
       "   'youre',\n",
       "   'pretty',\n",
       "   'awesome'],\n",
       "  '1'),\n",
       " (['ltsad',\n",
       "   'level',\n",
       "   'is',\n",
       "   '3',\n",
       "   'i',\n",
       "   'was',\n",
       "   'writing',\n",
       "   'a',\n",
       "   'massive',\n",
       "   'blog',\n",
       "   'tweet',\n",
       "   'on',\n",
       "   'myspace',\n",
       "   'and',\n",
       "   'my',\n",
       "   'comp',\n",
       "   'shut',\n",
       "   'down',\n",
       "   'now',\n",
       "   'its',\n",
       "   'all',\n",
       "   'lost',\n",
       "   'lays',\n",
       "   'in',\n",
       "   'fetal',\n",
       "   'position'],\n",
       "  '0'),\n",
       " (['',\n",
       "   '',\n",
       "   'headed',\n",
       "   'to',\n",
       "   'hospitol',\n",
       "   '',\n",
       "   'had',\n",
       "   'to',\n",
       "   'pull',\n",
       "   'out',\n",
       "   'of',\n",
       "   'the',\n",
       "   'golf',\n",
       "   'tourny',\n",
       "   'in',\n",
       "   '3rd',\n",
       "   'place',\n",
       "   'i',\n",
       "   'think',\n",
       "   'i',\n",
       "   'reripped',\n",
       "   'something',\n",
       "   '',\n",
       "   'yeah',\n",
       "   'that',\n",
       "   ''],\n",
       "  '0'),\n",
       " (['boring',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   'whats',\n",
       "   'wrong',\n",
       "   'with',\n",
       "   'him',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   'please',\n",
       "   'tell',\n",
       "   'me',\n",
       "   '',\n",
       "   '',\n",
       "   ''],\n",
       "  '0'),\n",
       " (['cant',\n",
       "   'be',\n",
       "   'bothered',\n",
       "   'i',\n",
       "   'wish',\n",
       "   'i',\n",
       "   'could',\n",
       "   'spend',\n",
       "   'the',\n",
       "   'rest',\n",
       "   'of',\n",
       "   'my',\n",
       "   'life',\n",
       "   'just',\n",
       "   'sat',\n",
       "   'here',\n",
       "   'and',\n",
       "   'going',\n",
       "   'to',\n",
       "   'gigs',\n",
       "   'seriously'],\n",
       "  '0'),\n",
       " (['',\n",
       "   '',\n",
       "   '',\n",
       "   'feeeling',\n",
       "   'like',\n",
       "   'shit',\n",
       "   'right',\n",
       "   'now',\n",
       "   'i',\n",
       "   'really',\n",
       "   'want',\n",
       "   'to',\n",
       "   'sleep'],\n",
       "  '0'),\n",
       " (['', '', '', 'goodbye', 'exams'], '1'),\n",
       " (['i',\n",
       "   'didnt',\n",
       "   'realize',\n",
       "   'it',\n",
       "   'was',\n",
       "   'that',\n",
       "   'deep',\n",
       "   'geez',\n",
       "   'give',\n",
       "   'a',\n",
       "   'girl',\n",
       "   'a',\n",
       "   'warning',\n",
       "   'atleast'],\n",
       "  '0'),\n",
       " (['i',\n",
       "   'hate',\n",
       "   'it',\n",
       "   'when',\n",
       "   'any',\n",
       "   'athlete',\n",
       "   'appears',\n",
       "   'to',\n",
       "   'tear',\n",
       "   'an',\n",
       "   'acl',\n",
       "   'on',\n",
       "   'live',\n",
       "   'television'],\n",
       "  '0'),\n",
       " (['i',\n",
       "   'miss',\n",
       "   'you',\n",
       "   'guys',\n",
       "   'too',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   'i',\n",
       "   'think',\n",
       "   'im',\n",
       "   'wearing',\n",
       "   'skinny',\n",
       "   'jeans',\n",
       "   'a',\n",
       "   'cute',\n",
       "   'sweater',\n",
       "   'and',\n",
       "   'heels',\n",
       "   '',\n",
       "   '',\n",
       "   'not',\n",
       "   'really',\n",
       "   'sure',\n",
       "   '',\n",
       "   '',\n",
       "   'what',\n",
       "   'are',\n",
       "   'you',\n",
       "   'doing',\n",
       "   'today'],\n",
       "  '0'),\n",
       " (['', 'meet', 'your', 'meat', 'httpbitly15ssci'], '0'),\n",
       " (['my', 'horsie', 'is', 'moving', 'on', 'saturday', 'morning'], '0'),\n",
       " (['no', 'sat', 'offneed', 'to', 'work', '6', 'days', 'a', 'week'], '0'),\n",
       " (['really',\n",
       "   'dont',\n",
       "   'like',\n",
       "   'doing',\n",
       "   'my',\n",
       "   'room',\n",
       "   'its',\n",
       "   'so',\n",
       "   'boring',\n",
       "   '',\n",
       "   'sick',\n",
       "   'of',\n",
       "   'doing',\n",
       "   'my',\n",
       "   'wardrobe',\n",
       "   'out',\n",
       "   'cant',\n",
       "   'waiit',\n",
       "   'till',\n",
       "   'i',\n",
       "   'have',\n",
       "   'my',\n",
       "   'walk',\n",
       "   'in',\n",
       "   'one',\n",
       "   '',\n",
       "   'yay'],\n",
       "  '0'),\n",
       " (['', '', '', 'sox', '', '', '', '', 'floyd', 'was', 'great'], '0'),\n",
       " (['times', 'by', 'like', 'a', 'million'], '0'),\n",
       " (['uploading', 'pictures', 'on', 'friendster'], '1'),\n",
       " (['what',\n",
       "   'type',\n",
       "   'of',\n",
       "   'a',\n",
       "   'spaz',\n",
       "   'downloads',\n",
       "   'a',\n",
       "   'virus',\n",
       "   'my',\n",
       "   'brother',\n",
       "   'thats',\n",
       "   'who',\n",
       "   '',\n",
       "   'msn',\n",
       "   'is',\n",
       "   'now',\n",
       "   'fucked',\n",
       "   'forever',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   ''],\n",
       "  '0'),\n",
       " (['ampampfightiin', 'wiit', 'the', 'babes'], '0'),\n",
       " (['',\n",
       "   '',\n",
       "   '',\n",
       "   'so',\n",
       "   'i',\n",
       "   'wrote',\n",
       "   'something',\n",
       "   'last',\n",
       "   'week',\n",
       "   'and',\n",
       "   'i',\n",
       "   'got',\n",
       "   'a',\n",
       "   'call',\n",
       "   'from',\n",
       "   'someone',\n",
       "   'in',\n",
       "   'the',\n",
       "   'new',\n",
       "   'york',\n",
       "   'office',\n",
       "   'httptumblrcomxcn21w6o7'],\n",
       "  '1'),\n",
       " (['enough', 'said'], '0'),\n",
       " (['',\n",
       "   '',\n",
       "   '',\n",
       "   'do',\n",
       "   'i',\n",
       "   'need',\n",
       "   'to',\n",
       "   'even',\n",
       "   'say',\n",
       "   'it',\n",
       "   '',\n",
       "   'do',\n",
       "   'i',\n",
       "   '',\n",
       "   'well'],\n",
       "  '1'),\n",
       " (['', 'health', 'class', 'what', 'a', 'joke'], '1'),\n",
       " (['ginaaa', 'lt3', 'go', 'to', 'the', 'show', 'tonight'], '1'),\n",
       " (['spiralgalaxy',\n",
       "   'ymptweet',\n",
       "   '',\n",
       "   'it',\n",
       "   'really',\n",
       "   'makes',\n",
       "   'me',\n",
       "   'sad',\n",
       "   'when',\n",
       "   'i',\n",
       "   'look',\n",
       "   'at',\n",
       "   'muslims',\n",
       "   'reality',\n",
       "   'now'],\n",
       "  '0'),\n",
       " (['',\n",
       "   'all',\n",
       "   'time',\n",
       "   'low',\n",
       "   'shall',\n",
       "   'be',\n",
       "   'my',\n",
       "   'motivation',\n",
       "   'for',\n",
       "   'the',\n",
       "   'rest',\n",
       "   'of',\n",
       "   'the',\n",
       "   'week'],\n",
       "  '0'),\n",
       " (['', '', 'and', 'the', 'entertainment', 'is', 'over'], '0'),\n",
       " (['another',\n",
       "   'year',\n",
       "   'of',\n",
       "   'lakers',\n",
       "   '',\n",
       "   'thats',\n",
       "   'neither',\n",
       "   'magic',\n",
       "   'nor',\n",
       "   'fun',\n",
       "   ''],\n",
       "  '0')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_treino.take(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria um objeto SentimentAnalyzer do pacote NLTK\n",
    "sentiment_analyzer = SentimentAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vamos usar o NLTK para remover as StopWords, The , a , ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando as stopwords do pacote NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/bulka/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Certifique-se de ter espaço em disco - Aproximadamente 5GB\n",
    "# https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n",
    "# nltk.download()\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"ntlkdata.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url = 'ntlkdata.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtém a lista de stopwords em Inglês e as coloca na lista Stopwords_all\n",
    "stopwords_all = []\n",
    "for word in stopwords.words('english'):\n",
    "  stopwords_all.append(word)\n",
    "  stopwords_all.append(word + '_NEG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'i_NEG',\n",
       " 'me',\n",
       " 'me_NEG',\n",
       " 'my',\n",
       " 'my_NEG',\n",
       " 'myself',\n",
       " 'myself_NEG',\n",
       " 'we',\n",
       " 'we_NEG',\n",
       " 'our',\n",
       " 'our_NEG',\n",
       " 'ours',\n",
       " 'ours_NEG',\n",
       " 'ourselves',\n",
       " 'ourselves_NEG',\n",
       " 'you',\n",
       " 'you_NEG',\n",
       " \"you're\",\n",
       " \"you're_NEG\",\n",
       " \"you've\",\n",
       " \"you've_NEG\",\n",
       " \"you'll\",\n",
       " \"you'll_NEG\",\n",
       " \"you'd\",\n",
       " \"you'd_NEG\",\n",
       " 'your',\n",
       " 'your_NEG',\n",
       " 'yours',\n",
       " 'yours_NEG',\n",
       " 'yourself',\n",
       " 'yourself_NEG',\n",
       " 'yourselves',\n",
       " 'yourselves_NEG',\n",
       " 'he',\n",
       " 'he_NEG',\n",
       " 'him',\n",
       " 'him_NEG',\n",
       " 'his',\n",
       " 'his_NEG',\n",
       " 'himself',\n",
       " 'himself_NEG',\n",
       " 'she',\n",
       " 'she_NEG',\n",
       " \"she's\",\n",
       " \"she's_NEG\",\n",
       " 'her',\n",
       " 'her_NEG',\n",
       " 'hers',\n",
       " 'hers_NEG',\n",
       " 'herself',\n",
       " 'herself_NEG',\n",
       " 'it',\n",
       " 'it_NEG',\n",
       " \"it's\",\n",
       " \"it's_NEG\",\n",
       " 'its',\n",
       " 'its_NEG',\n",
       " 'itself',\n",
       " 'itself_NEG',\n",
       " 'they',\n",
       " 'they_NEG',\n",
       " 'them',\n",
       " 'them_NEG',\n",
       " 'their',\n",
       " 'their_NEG',\n",
       " 'theirs',\n",
       " 'theirs_NEG',\n",
       " 'themselves',\n",
       " 'themselves_NEG',\n",
       " 'what',\n",
       " 'what_NEG',\n",
       " 'which',\n",
       " 'which_NEG',\n",
       " 'who',\n",
       " 'who_NEG',\n",
       " 'whom',\n",
       " 'whom_NEG',\n",
       " 'this',\n",
       " 'this_NEG',\n",
       " 'that',\n",
       " 'that_NEG',\n",
       " \"that'll\",\n",
       " \"that'll_NEG\",\n",
       " 'these',\n",
       " 'these_NEG',\n",
       " 'those',\n",
       " 'those_NEG',\n",
       " 'am',\n",
       " 'am_NEG',\n",
       " 'is',\n",
       " 'is_NEG',\n",
       " 'are',\n",
       " 'are_NEG',\n",
       " 'was',\n",
       " 'was_NEG',\n",
       " 'were',\n",
       " 'were_NEG',\n",
       " 'be',\n",
       " 'be_NEG',\n",
       " 'been',\n",
       " 'been_NEG',\n",
       " 'being',\n",
       " 'being_NEG',\n",
       " 'have',\n",
       " 'have_NEG',\n",
       " 'has',\n",
       " 'has_NEG',\n",
       " 'had',\n",
       " 'had_NEG',\n",
       " 'having',\n",
       " 'having_NEG',\n",
       " 'do',\n",
       " 'do_NEG',\n",
       " 'does',\n",
       " 'does_NEG',\n",
       " 'did',\n",
       " 'did_NEG',\n",
       " 'doing',\n",
       " 'doing_NEG',\n",
       " 'a',\n",
       " 'a_NEG',\n",
       " 'an',\n",
       " 'an_NEG',\n",
       " 'the',\n",
       " 'the_NEG',\n",
       " 'and',\n",
       " 'and_NEG',\n",
       " 'but',\n",
       " 'but_NEG',\n",
       " 'if',\n",
       " 'if_NEG',\n",
       " 'or',\n",
       " 'or_NEG',\n",
       " 'because',\n",
       " 'because_NEG',\n",
       " 'as',\n",
       " 'as_NEG',\n",
       " 'until',\n",
       " 'until_NEG',\n",
       " 'while',\n",
       " 'while_NEG',\n",
       " 'of',\n",
       " 'of_NEG',\n",
       " 'at',\n",
       " 'at_NEG',\n",
       " 'by',\n",
       " 'by_NEG',\n",
       " 'for',\n",
       " 'for_NEG',\n",
       " 'with',\n",
       " 'with_NEG',\n",
       " 'about',\n",
       " 'about_NEG',\n",
       " 'against',\n",
       " 'against_NEG',\n",
       " 'between',\n",
       " 'between_NEG',\n",
       " 'into',\n",
       " 'into_NEG',\n",
       " 'through',\n",
       " 'through_NEG',\n",
       " 'during',\n",
       " 'during_NEG',\n",
       " 'before',\n",
       " 'before_NEG',\n",
       " 'after',\n",
       " 'after_NEG',\n",
       " 'above',\n",
       " 'above_NEG',\n",
       " 'below',\n",
       " 'below_NEG',\n",
       " 'to',\n",
       " 'to_NEG',\n",
       " 'from',\n",
       " 'from_NEG',\n",
       " 'up',\n",
       " 'up_NEG',\n",
       " 'down',\n",
       " 'down_NEG',\n",
       " 'in',\n",
       " 'in_NEG',\n",
       " 'out',\n",
       " 'out_NEG',\n",
       " 'on',\n",
       " 'on_NEG',\n",
       " 'off',\n",
       " 'off_NEG',\n",
       " 'over',\n",
       " 'over_NEG',\n",
       " 'under',\n",
       " 'under_NEG',\n",
       " 'again',\n",
       " 'again_NEG',\n",
       " 'further',\n",
       " 'further_NEG',\n",
       " 'then',\n",
       " 'then_NEG',\n",
       " 'once',\n",
       " 'once_NEG',\n",
       " 'here',\n",
       " 'here_NEG',\n",
       " 'there',\n",
       " 'there_NEG',\n",
       " 'when',\n",
       " 'when_NEG',\n",
       " 'where',\n",
       " 'where_NEG',\n",
       " 'why',\n",
       " 'why_NEG',\n",
       " 'how',\n",
       " 'how_NEG',\n",
       " 'all',\n",
       " 'all_NEG',\n",
       " 'any',\n",
       " 'any_NEG',\n",
       " 'both',\n",
       " 'both_NEG',\n",
       " 'each',\n",
       " 'each_NEG',\n",
       " 'few',\n",
       " 'few_NEG',\n",
       " 'more',\n",
       " 'more_NEG',\n",
       " 'most',\n",
       " 'most_NEG',\n",
       " 'other',\n",
       " 'other_NEG',\n",
       " 'some',\n",
       " 'some_NEG',\n",
       " 'such',\n",
       " 'such_NEG',\n",
       " 'no',\n",
       " 'no_NEG',\n",
       " 'nor',\n",
       " 'nor_NEG',\n",
       " 'not',\n",
       " 'not_NEG',\n",
       " 'only',\n",
       " 'only_NEG',\n",
       " 'own',\n",
       " 'own_NEG',\n",
       " 'same',\n",
       " 'same_NEG',\n",
       " 'so',\n",
       " 'so_NEG',\n",
       " 'than',\n",
       " 'than_NEG',\n",
       " 'too',\n",
       " 'too_NEG',\n",
       " 'very',\n",
       " 'very_NEG',\n",
       " 's',\n",
       " 's_NEG',\n",
       " 't',\n",
       " 't_NEG',\n",
       " 'can',\n",
       " 'can_NEG',\n",
       " 'will',\n",
       " 'will_NEG',\n",
       " 'just',\n",
       " 'just_NEG',\n",
       " 'don',\n",
       " 'don_NEG',\n",
       " \"don't\",\n",
       " \"don't_NEG\",\n",
       " 'should',\n",
       " 'should_NEG',\n",
       " \"should've\",\n",
       " \"should've_NEG\",\n",
       " 'now',\n",
       " 'now_NEG',\n",
       " 'd',\n",
       " 'd_NEG',\n",
       " 'll',\n",
       " 'll_NEG',\n",
       " 'm',\n",
       " 'm_NEG',\n",
       " 'o',\n",
       " 'o_NEG',\n",
       " 're',\n",
       " 're_NEG',\n",
       " 've',\n",
       " 've_NEG',\n",
       " 'y',\n",
       " 'y_NEG',\n",
       " 'ain',\n",
       " 'ain_NEG',\n",
       " 'aren',\n",
       " 'aren_NEG',\n",
       " \"aren't\",\n",
       " \"aren't_NEG\",\n",
       " 'couldn',\n",
       " 'couldn_NEG',\n",
       " \"couldn't\",\n",
       " \"couldn't_NEG\",\n",
       " 'didn',\n",
       " 'didn_NEG',\n",
       " \"didn't\",\n",
       " \"didn't_NEG\",\n",
       " 'doesn',\n",
       " 'doesn_NEG',\n",
       " \"doesn't\",\n",
       " \"doesn't_NEG\",\n",
       " 'hadn',\n",
       " 'hadn_NEG',\n",
       " \"hadn't\",\n",
       " \"hadn't_NEG\",\n",
       " 'hasn',\n",
       " 'hasn_NEG',\n",
       " \"hasn't\",\n",
       " \"hasn't_NEG\",\n",
       " 'haven',\n",
       " 'haven_NEG',\n",
       " \"haven't\",\n",
       " \"haven't_NEG\",\n",
       " 'isn',\n",
       " 'isn_NEG',\n",
       " \"isn't\",\n",
       " \"isn't_NEG\",\n",
       " 'ma',\n",
       " 'ma_NEG',\n",
       " 'mightn',\n",
       " 'mightn_NEG',\n",
       " \"mightn't\",\n",
       " \"mightn't_NEG\",\n",
       " 'mustn',\n",
       " 'mustn_NEG',\n",
       " \"mustn't\",\n",
       " \"mustn't_NEG\",\n",
       " 'needn',\n",
       " 'needn_NEG',\n",
       " \"needn't\",\n",
       " \"needn't_NEG\",\n",
       " 'shan',\n",
       " 'shan_NEG',\n",
       " \"shan't\",\n",
       " \"shan't_NEG\",\n",
       " 'shouldn',\n",
       " 'shouldn_NEG',\n",
       " \"shouldn't\",\n",
       " \"shouldn't_NEG\",\n",
       " 'wasn',\n",
       " 'wasn_NEG',\n",
       " \"wasn't\",\n",
       " \"wasn't_NEG\",\n",
       " 'weren',\n",
       " 'weren_NEG',\n",
       " \"weren't\",\n",
       " \"weren't_NEG\",\n",
       " 'won',\n",
       " 'won_NEG',\n",
       " \"won't\",\n",
       " \"won't_NEG\",\n",
       " 'wouldn',\n",
       " 'wouldn_NEG',\n",
       " \"wouldn't\",\n",
       " \"wouldn't_NEG\"]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtém 10.000 tweets do dataset de treino\n",
    "dataset_treino_amostra = dataset_treino.take(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos retornar todas as palavras dessas 10000 linhas que não são stopwords\n",
    "# Usando o sentiment analyser do NTlK e sua função All words \n",
    "all_words_neg = sentiment_analyzer.all_words([mark_negation(doc) for doc in dataset_treino_amostra])\n",
    "all_words_neg_nostops = [x for x in all_words_neg if x not in stopwords_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is',\n",
       " 'so',\n",
       " 'sad',\n",
       " 'for',\n",
       " 'my',\n",
       " 'apl',\n",
       " 'friend',\n",
       " 'i',\n",
       " 'missed',\n",
       " 'the',\n",
       " 'new',\n",
       " 'moon',\n",
       " 'trailer',\n",
       " 'omg',\n",
       " 'its',\n",
       " 'already',\n",
       " '730',\n",
       " 'o',\n",
       " '',\n",
       " 'omgaga',\n",
       " 'im',\n",
       " 'sooo',\n",
       " '',\n",
       " 'im',\n",
       " 'gunna',\n",
       " 'cry',\n",
       " 'ive',\n",
       " 'been',\n",
       " 'at',\n",
       " 'this',\n",
       " 'dentist',\n",
       " 'since',\n",
       " '11',\n",
       " 'i',\n",
       " 'was',\n",
       " 'suposed',\n",
       " '2',\n",
       " 'just',\n",
       " 'get',\n",
       " 'a',\n",
       " 'crown',\n",
       " 'put',\n",
       " 'on',\n",
       " '30mins',\n",
       " 'i',\n",
       " 'think',\n",
       " 'mi',\n",
       " 'bf',\n",
       " 'is',\n",
       " 'cheating',\n",
       " 'on',\n",
       " 'me',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'tt',\n",
       " 'or',\n",
       " 'i',\n",
       " 'just',\n",
       " 'worry',\n",
       " 'too',\n",
       " 'much',\n",
       " 'juuuuuuuuuuuuuuuuussssst',\n",
       " 'chillin',\n",
       " 'sunny',\n",
       " 'again',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'work',\n",
       " 'tomorrow',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'tv',\n",
       " 'tonight',\n",
       " 'handed',\n",
       " 'in',\n",
       " 'my',\n",
       " 'uniform',\n",
       " 'today',\n",
       " '',\n",
       " 'i',\n",
       " 'miss',\n",
       " 'you',\n",
       " 'already',\n",
       " 'hmmmm',\n",
       " 'i',\n",
       " 'wonder',\n",
       " 'how',\n",
       " 'she',\n",
       " 'my',\n",
       " 'number',\n",
       " '',\n",
       " 'i',\n",
       " 'must',\n",
       " 'think',\n",
       " 'about',\n",
       " 'positive',\n",
       " 'thanks',\n",
       " 'to',\n",
       " 'all',\n",
       " 'the',\n",
       " 'haters',\n",
       " 'up',\n",
       " 'in',\n",
       " 'my',\n",
       " 'face',\n",
       " 'all',\n",
       " 'day',\n",
       " '112102',\n",
       " 'this',\n",
       " 'weekend',\n",
       " 'has',\n",
       " 'sucked',\n",
       " 'so',\n",
       " 'far',\n",
       " 'jb',\n",
       " 'isnt',\n",
       " 'showing_NEG',\n",
       " 'in_NEG',\n",
       " 'australia_NEG',\n",
       " 'any_NEG',\n",
       " 'more_NEG',\n",
       " 'ok',\n",
       " 'thats',\n",
       " 'it',\n",
       " 'you',\n",
       " 'win',\n",
       " 'lt',\n",
       " 'this',\n",
       " 'is',\n",
       " 'the',\n",
       " 'way',\n",
       " 'i',\n",
       " 'feel',\n",
       " 'right',\n",
       " 'now',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'awhhe',\n",
       " 'man',\n",
       " 'im',\n",
       " 'completely',\n",
       " 'useless',\n",
       " 'rt',\n",
       " 'now',\n",
       " 'funny',\n",
       " 'feeling',\n",
       " 'strangely',\n",
       " 'fine',\n",
       " 'now',\n",
       " 'im',\n",
       " 'gonna',\n",
       " 'go',\n",
       " 'listen',\n",
       " 'to',\n",
       " 'some',\n",
       " 'semisonic',\n",
       " 'to',\n",
       " 'celebrate',\n",
       " 'huge',\n",
       " 'roll',\n",
       " 'of',\n",
       " 'thunder',\n",
       " 'just',\n",
       " 'nowso',\n",
       " 'scary',\n",
       " 'i',\n",
       " 'just',\n",
       " 'cut',\n",
       " 'my',\n",
       " 'beard',\n",
       " 'off',\n",
       " 'its',\n",
       " 'only',\n",
       " 'been',\n",
       " 'growing',\n",
       " 'for',\n",
       " 'well',\n",
       " 'over',\n",
       " 'a',\n",
       " 'year',\n",
       " 'im',\n",
       " 'gonna',\n",
       " 'start',\n",
       " 'it',\n",
       " 'over',\n",
       " 'shaunamanu',\n",
       " 'is',\n",
       " 'happy',\n",
       " 'in',\n",
       " 'the',\n",
       " 'meantime',\n",
       " 'very',\n",
       " 'sad',\n",
       " 'about',\n",
       " 'iran',\n",
       " 'wompppp',\n",
       " 'wompp',\n",
       " 'youre',\n",
       " 'the',\n",
       " 'only',\n",
       " 'one',\n",
       " 'who',\n",
       " 'can',\n",
       " 'see',\n",
       " 'this',\n",
       " 'cause',\n",
       " 'no',\n",
       " 'one_NEG',\n",
       " 'else_NEG',\n",
       " 'is_NEG',\n",
       " 'following_NEG',\n",
       " 'me_NEG',\n",
       " 'this_NEG',\n",
       " 'is_NEG',\n",
       " 'for_NEG',\n",
       " 'you_NEG',\n",
       " 'because_NEG',\n",
       " 'youre_NEG',\n",
       " 'pretty_NEG',\n",
       " 'awesome_NEG',\n",
       " 'ltsad',\n",
       " 'level',\n",
       " 'is',\n",
       " '3',\n",
       " 'i',\n",
       " 'was',\n",
       " 'writing',\n",
       " 'a',\n",
       " 'massive',\n",
       " 'blog',\n",
       " 'tweet',\n",
       " 'on',\n",
       " 'myspace',\n",
       " 'and',\n",
       " 'my',\n",
       " 'comp',\n",
       " 'shut',\n",
       " 'down',\n",
       " 'now',\n",
       " 'its',\n",
       " 'all',\n",
       " 'lost',\n",
       " 'lays',\n",
       " 'in',\n",
       " 'fetal',\n",
       " 'position',\n",
       " '',\n",
       " '',\n",
       " 'headed',\n",
       " 'to',\n",
       " 'hospitol',\n",
       " '',\n",
       " 'had',\n",
       " 'to',\n",
       " 'pull',\n",
       " 'out',\n",
       " 'of',\n",
       " 'the',\n",
       " 'golf',\n",
       " 'tourny',\n",
       " 'in',\n",
       " '3rd',\n",
       " 'place',\n",
       " 'i',\n",
       " 'think',\n",
       " 'i',\n",
       " 'reripped',\n",
       " 'something',\n",
       " '',\n",
       " 'yeah',\n",
       " 'that',\n",
       " '',\n",
       " 'boring',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'whats',\n",
       " 'wrong',\n",
       " 'with',\n",
       " 'him',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'please',\n",
       " 'tell',\n",
       " 'me',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'cant',\n",
       " 'be_NEG',\n",
       " 'bothered_NEG',\n",
       " 'i_NEG',\n",
       " 'wish_NEG',\n",
       " 'i_NEG',\n",
       " 'could_NEG',\n",
       " 'spend_NEG',\n",
       " 'the_NEG',\n",
       " 'rest_NEG',\n",
       " 'of_NEG',\n",
       " 'my_NEG',\n",
       " 'life_NEG',\n",
       " 'just_NEG',\n",
       " 'sat_NEG',\n",
       " 'here_NEG',\n",
       " 'and_NEG',\n",
       " 'going_NEG',\n",
       " 'to_NEG',\n",
       " 'gigs_NEG',\n",
       " 'seriously_NEG',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'feeeling',\n",
       " 'like',\n",
       " 'shit',\n",
       " 'right',\n",
       " 'now',\n",
       " 'i',\n",
       " 'really',\n",
       " 'want',\n",
       " 'to',\n",
       " 'sleep',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'goodbye',\n",
       " 'exams',\n",
       " 'i',\n",
       " 'didnt',\n",
       " 'realize_NEG',\n",
       " 'it_NEG',\n",
       " 'was_NEG',\n",
       " 'that_NEG',\n",
       " 'deep_NEG',\n",
       " 'geez_NEG',\n",
       " 'give_NEG',\n",
       " 'a_NEG',\n",
       " 'girl_NEG',\n",
       " 'a_NEG',\n",
       " 'warning_NEG',\n",
       " 'atleast_NEG',\n",
       " 'i',\n",
       " 'hate',\n",
       " 'it',\n",
       " 'when',\n",
       " 'any',\n",
       " 'athlete',\n",
       " 'appears',\n",
       " 'to',\n",
       " 'tear',\n",
       " 'an',\n",
       " 'acl',\n",
       " 'on',\n",
       " 'live',\n",
       " 'television',\n",
       " 'i',\n",
       " 'miss',\n",
       " 'you',\n",
       " 'guys',\n",
       " 'too',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'i',\n",
       " 'think',\n",
       " 'im',\n",
       " 'wearing',\n",
       " 'skinny',\n",
       " 'jeans',\n",
       " 'a',\n",
       " 'cute',\n",
       " 'sweater',\n",
       " 'and',\n",
       " 'heels',\n",
       " '',\n",
       " '',\n",
       " 'not',\n",
       " 'really_NEG',\n",
       " 'sure_NEG',\n",
       " '_NEG',\n",
       " '_NEG',\n",
       " 'what_NEG',\n",
       " 'are_NEG',\n",
       " 'you_NEG',\n",
       " 'doing_NEG',\n",
       " 'today_NEG',\n",
       " '',\n",
       " 'meet',\n",
       " 'your',\n",
       " 'meat',\n",
       " 'httpbitly15ssci',\n",
       " 'my',\n",
       " 'horsie',\n",
       " 'is',\n",
       " 'moving',\n",
       " 'on',\n",
       " 'saturday',\n",
       " 'morning',\n",
       " 'no',\n",
       " 'sat_NEG',\n",
       " 'offneed_NEG',\n",
       " 'to_NEG',\n",
       " 'work_NEG',\n",
       " '6_NEG',\n",
       " 'days_NEG',\n",
       " 'a_NEG',\n",
       " 'week_NEG',\n",
       " 'really',\n",
       " 'dont',\n",
       " 'like_NEG',\n",
       " 'doing_NEG',\n",
       " 'my_NEG',\n",
       " 'room_NEG',\n",
       " 'its_NEG',\n",
       " 'so_NEG',\n",
       " 'boring_NEG',\n",
       " '_NEG',\n",
       " 'sick_NEG',\n",
       " 'of_NEG',\n",
       " 'doing_NEG',\n",
       " 'my_NEG',\n",
       " 'wardrobe_NEG',\n",
       " 'out_NEG',\n",
       " 'cant_NEG',\n",
       " 'waiit_NEG',\n",
       " 'till_NEG',\n",
       " 'i_NEG',\n",
       " 'have_NEG',\n",
       " 'my_NEG',\n",
       " 'walk_NEG',\n",
       " 'in_NEG',\n",
       " 'one_NEG',\n",
       " '_NEG',\n",
       " 'yay_NEG',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'sox',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'floyd',\n",
       " 'was',\n",
       " 'great',\n",
       " 'times',\n",
       " 'by',\n",
       " 'like',\n",
       " 'a',\n",
       " 'million',\n",
       " 'uploading',\n",
       " 'pictures',\n",
       " 'on',\n",
       " 'friendster',\n",
       " 'what',\n",
       " 'type',\n",
       " 'of',\n",
       " 'a',\n",
       " 'spaz',\n",
       " 'downloads',\n",
       " 'a',\n",
       " 'virus',\n",
       " 'my',\n",
       " 'brother',\n",
       " 'thats',\n",
       " 'who',\n",
       " '',\n",
       " 'msn',\n",
       " 'is',\n",
       " 'now',\n",
       " 'fucked',\n",
       " 'forever',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'ampampfightiin',\n",
       " 'wiit',\n",
       " 'the',\n",
       " 'babes',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'so',\n",
       " 'i',\n",
       " 'wrote',\n",
       " 'something',\n",
       " 'last',\n",
       " 'week',\n",
       " 'and',\n",
       " 'i',\n",
       " 'got',\n",
       " 'a',\n",
       " 'call',\n",
       " 'from',\n",
       " 'someone',\n",
       " 'in',\n",
       " 'the',\n",
       " 'new',\n",
       " 'york',\n",
       " 'office',\n",
       " 'httptumblrcomxcn21w6o7',\n",
       " 'enough',\n",
       " 'said',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'do',\n",
       " 'i',\n",
       " 'need',\n",
       " 'to',\n",
       " 'even',\n",
       " 'say',\n",
       " 'it',\n",
       " '',\n",
       " 'do',\n",
       " 'i',\n",
       " '',\n",
       " 'well',\n",
       " '',\n",
       " 'health',\n",
       " 'class',\n",
       " 'what',\n",
       " 'a',\n",
       " 'joke',\n",
       " 'ginaaa',\n",
       " 'lt3',\n",
       " 'go',\n",
       " 'to',\n",
       " 'the',\n",
       " 'show',\n",
       " 'tonight',\n",
       " 'spiralgalaxy',\n",
       " 'ymptweet',\n",
       " '',\n",
       " 'it',\n",
       " 'really',\n",
       " 'makes',\n",
       " 'me',\n",
       " 'sad',\n",
       " 'when',\n",
       " 'i',\n",
       " 'look',\n",
       " 'at',\n",
       " 'muslims',\n",
       " 'reality',\n",
       " 'now',\n",
       " '',\n",
       " 'all',\n",
       " 'time',\n",
       " 'low',\n",
       " 'shall',\n",
       " 'be',\n",
       " 'my',\n",
       " 'motivation',\n",
       " 'for',\n",
       " 'the',\n",
       " 'rest',\n",
       " 'of',\n",
       " 'the',\n",
       " 'week',\n",
       " '',\n",
       " '',\n",
       " 'and',\n",
       " 'the',\n",
       " 'entertainment',\n",
       " 'is',\n",
       " 'over',\n",
       " 'another',\n",
       " 'year',\n",
       " 'of',\n",
       " 'lakers',\n",
       " '',\n",
       " 'thats',\n",
       " 'neither',\n",
       " 'magic',\n",
       " 'nor',\n",
       " 'fun',\n",
       " '',\n",
       " 'baddest',\n",
       " 'day',\n",
       " 'eveer',\n",
       " 'bathroom',\n",
       " 'is',\n",
       " 'clean',\n",
       " 'now',\n",
       " 'on',\n",
       " 'to',\n",
       " 'more',\n",
       " 'enjoyable',\n",
       " 'tasks',\n",
       " 'boom',\n",
       " 'boom',\n",
       " 'pow',\n",
       " 'but',\n",
       " 'im',\n",
       " 'proud',\n",
       " 'congrats',\n",
       " 'to',\n",
       " 'helio',\n",
       " 'though',\n",
       " 'david',\n",
       " 'must',\n",
       " 'be',\n",
       " 'hospitalized',\n",
       " 'for',\n",
       " 'five',\n",
       " 'days',\n",
       " 'end',\n",
       " 'of',\n",
       " 'july',\n",
       " 'palatine',\n",
       " 'tonsils',\n",
       " 'i',\n",
       " 'will',\n",
       " 'probably',\n",
       " 'never',\n",
       " 'see_NEG',\n",
       " 'katie_NEG',\n",
       " 'in_NEG',\n",
       " 'concert_NEG',\n",
       " 'friends',\n",
       " 'are',\n",
       " 'leaving',\n",
       " 'me',\n",
       " 'cause',\n",
       " 'of',\n",
       " 'this',\n",
       " 'stupid',\n",
       " 'love',\n",
       " '',\n",
       " 'httpbitlyzoxzc',\n",
       " 'go',\n",
       " 'give',\n",
       " 'ur',\n",
       " 'mom',\n",
       " 'a',\n",
       " 'hug',\n",
       " 'right',\n",
       " 'now',\n",
       " 'httpbitlyazfwv',\n",
       " 'going',\n",
       " 'to',\n",
       " 'see',\n",
       " 'harry',\n",
       " 'sunday',\n",
       " 'happiness',\n",
       " 'hand',\n",
       " 'quilting',\n",
       " 'it',\n",
       " 'is',\n",
       " 'then',\n",
       " 'hate',\n",
       " 'u',\n",
       " '',\n",
       " '',\n",
       " 'leysh',\n",
       " 't9ar5',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'i',\n",
       " 'always',\n",
       " 'get',\n",
       " 'what',\n",
       " 'i',\n",
       " 'want',\n",
       " 'i',\n",
       " 'bend',\n",
       " 'backwards',\n",
       " 'i',\n",
       " 'get',\n",
       " 'off',\n",
       " 'work',\n",
       " 'sooooon',\n",
       " 'i',\n",
       " 'miss',\n",
       " 'cody',\n",
       " 'booo',\n",
       " 'havent',\n",
       " 'seen_NEG',\n",
       " 'him_NEG',\n",
       " 'in_NEG',\n",
       " 'foreverr_NEG',\n",
       " 'i',\n",
       " 'hate',\n",
       " 'allergies',\n",
       " 'should',\n",
       " 'i',\n",
       " 'get',\n",
       " 'my',\n",
       " 'hair',\n",
       " 'cut',\n",
       " 'tomorrow',\n",
       " 'im',\n",
       " 'taking',\n",
       " 'a',\n",
       " 'public',\n",
       " 'poll',\n",
       " '',\n",
       " 'i',\n",
       " 'love',\n",
       " 'you',\n",
       " 'guys',\n",
       " 'so',\n",
       " 'much',\n",
       " 'that',\n",
       " 'it',\n",
       " 'hurts',\n",
       " 'httptumblrcomxkh1z19us',\n",
       " 'i',\n",
       " 'miss',\n",
       " 'earl',\n",
       " 'i',\n",
       " 'miss',\n",
       " 'new',\n",
       " 'jersey',\n",
       " '',\n",
       " '',\n",
       " 'i',\n",
       " 'missed',\n",
       " 'the',\n",
       " 'first',\n",
       " 'hour',\n",
       " 'of',\n",
       " 'sytycd',\n",
       " 'last',\n",
       " 'night',\n",
       " 'i',\n",
       " 'need',\n",
       " 'a',\n",
       " 'u2',\n",
       " 'fix',\n",
       " 'now',\n",
       " 'i',\n",
       " 'never',\n",
       " 'thought_NEG',\n",
       " 'id_NEG',\n",
       " 'become_NEG',\n",
       " 'second_NEG',\n",
       " 'choice_NEG',\n",
       " 'i',\n",
       " 'think',\n",
       " 'i',\n",
       " 'may',\n",
       " 'be',\n",
       " 'too',\n",
       " 'friendlylol',\n",
       " 'o',\n",
       " 'well',\n",
       " 'i',\n",
       " 'think',\n",
       " 'manuel',\n",
       " 'my',\n",
       " 'basil',\n",
       " 'plant',\n",
       " 'only',\n",
       " 'has',\n",
       " 'days',\n",
       " 'to',\n",
       " 'live',\n",
       " 'i',\n",
       " 'wanna',\n",
       " 'be',\n",
       " 'at',\n",
       " 'home',\n",
       " '',\n",
       " 'churchi',\n",
       " 'wonder',\n",
       " 'wht',\n",
       " 'they',\n",
       " 'are',\n",
       " 'doing',\n",
       " 'i',\n",
       " 'wanna',\n",
       " 'make',\n",
       " 'my',\n",
       " 'own',\n",
       " 'pizza',\n",
       " '',\n",
       " '',\n",
       " 'i',\n",
       " 'want',\n",
       " 'a',\n",
       " '120gb',\n",
       " 'harddrive',\n",
       " 'i',\n",
       " 'want',\n",
       " 'a',\n",
       " 'hug',\n",
       " 'i',\n",
       " 'want',\n",
       " 'miley',\n",
       " 'to',\n",
       " 'tour',\n",
       " 'australia',\n",
       " 'i',\n",
       " 'wanted',\n",
       " 'to',\n",
       " 'sleep',\n",
       " 'in',\n",
       " 'this',\n",
       " 'morning',\n",
       " 'but',\n",
       " 'a',\n",
       " 'mean',\n",
       " 'kid',\n",
       " 'through',\n",
       " 'a',\n",
       " 'popsicle',\n",
       " 'stick',\n",
       " 'at',\n",
       " 'me',\n",
       " 'head',\n",
       " 'i',\n",
       " 'wish',\n",
       " 'i',\n",
       " 'could',\n",
       " 'fly',\n",
       " 'away',\n",
       " 'like',\n",
       " 'those',\n",
       " 'squirrels',\n",
       " 'i',\n",
       " 'was',\n",
       " 'too',\n",
       " 'slow',\n",
       " 'to',\n",
       " 'get',\n",
       " '1',\n",
       " 'up',\n",
       " 'tix',\n",
       " '',\n",
       " '',\n",
       " 'i',\n",
       " 'will',\n",
       " 'send',\n",
       " 'sunshine',\n",
       " 'to',\n",
       " 'northern',\n",
       " 'ireland',\n",
       " 'i',\n",
       " 'wish',\n",
       " 'i',\n",
       " 'could',\n",
       " 'go',\n",
       " 'to',\n",
       " 't4',\n",
       " 'on',\n",
       " 'the',\n",
       " 'beach',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'would',\n",
       " 'be',\n",
       " 'great',\n",
       " 'to',\n",
       " 'see',\n",
       " 'shontellelayne',\n",
       " 'amp',\n",
       " 'danmerriweather',\n",
       " '',\n",
       " '',\n",
       " 'i',\n",
       " 'would',\n",
       " 'be',\n",
       " 'so',\n",
       " 'much',\n",
       " 'happier',\n",
       " 'if',\n",
       " 'the',\n",
       " 'walls',\n",
       " 'of',\n",
       " 'my',\n",
       " 'bedroom',\n",
       " 'were',\n",
       " 'painted',\n",
       " 'white',\n",
       " 'idk',\n",
       " 'wat',\n",
       " '2',\n",
       " 'do',\n",
       " 'who',\n",
       " 'can',\n",
       " 'i',\n",
       " 'trust',\n",
       " 'me',\n",
       " 'im',\n",
       " 'sorry',\n",
       " '4',\n",
       " 'all',\n",
       " 'da',\n",
       " 'pain',\n",
       " 'i',\n",
       " 'have',\n",
       " 'caused',\n",
       " 'nebody',\n",
       " 'ima',\n",
       " 'take',\n",
       " 'dis',\n",
       " 'time',\n",
       " 'out',\n",
       " '2',\n",
       " 'straighten',\n",
       " 'myself',\n",
       " 'out',\n",
       " 'i',\n",
       " 'luv',\n",
       " 'yall',\n",
       " 'im',\n",
       " 'finding',\n",
       " 'the',\n",
       " 'intercept',\n",
       " 'slopeand',\n",
       " 'banging',\n",
       " 'my',\n",
       " 'head',\n",
       " 'against',\n",
       " 'the',\n",
       " 'wallmath',\n",
       " 'brain',\n",
       " 'heads',\n",
       " 'come',\n",
       " 'save',\n",
       " 'me',\n",
       " 'im',\n",
       " 'really',\n",
       " 'going',\n",
       " 'to',\n",
       " 'bed',\n",
       " 'now',\n",
       " 'im',\n",
       " 'sick',\n",
       " '',\n",
       " 'cough',\n",
       " 'cough',\n",
       " 'in',\n",
       " 'cab',\n",
       " 'headed',\n",
       " 'to',\n",
       " 'the',\n",
       " 'airport',\n",
       " '',\n",
       " 'going',\n",
       " 'home',\n",
       " 'ltchristygt',\n",
       " 'in',\n",
       " 'case',\n",
       " 'i',\n",
       " 'feel',\n",
       " 'emo',\n",
       " 'in',\n",
       " 'camp',\n",
       " 'feeling',\n",
       " 'a',\n",
       " 'wee',\n",
       " 'bit',\n",
       " 'of',\n",
       " 'it',\n",
       " 'alram',\n",
       " 'bringing',\n",
       " 'in',\n",
       " 'the',\n",
       " 'human',\n",
       " 'rights',\n",
       " 'watch',\n",
       " 'world',\n",
       " 'report',\n",
       " '2009hope',\n",
       " 'itll',\n",
       " 'work',\n",
       " 'jin',\n",
       " 'has',\n",
       " 'a',\n",
       " 'twitter',\n",
       " 'jonas',\n",
       " ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sad',\n",
       " 'apl',\n",
       " 'friend',\n",
       " 'missed',\n",
       " 'new',\n",
       " 'moon',\n",
       " 'trailer',\n",
       " 'omg',\n",
       " 'already',\n",
       " '730',\n",
       " '',\n",
       " 'omgaga',\n",
       " 'im',\n",
       " 'sooo',\n",
       " '',\n",
       " 'im',\n",
       " 'gunna',\n",
       " 'cry',\n",
       " 'ive',\n",
       " 'dentist',\n",
       " 'since',\n",
       " '11',\n",
       " 'suposed',\n",
       " '2',\n",
       " 'get',\n",
       " 'crown',\n",
       " 'put',\n",
       " '30mins',\n",
       " 'think',\n",
       " 'mi',\n",
       " 'bf',\n",
       " 'cheating',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'tt',\n",
       " 'worry',\n",
       " 'much',\n",
       " 'juuuuuuuuuuuuuuuuussssst',\n",
       " 'chillin',\n",
       " 'sunny',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'work',\n",
       " 'tomorrow',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'tv',\n",
       " 'tonight',\n",
       " 'handed',\n",
       " 'uniform',\n",
       " 'today',\n",
       " '',\n",
       " 'miss',\n",
       " 'already',\n",
       " 'hmmmm',\n",
       " 'wonder',\n",
       " 'number',\n",
       " '',\n",
       " 'must',\n",
       " 'think',\n",
       " 'positive',\n",
       " 'thanks',\n",
       " 'haters',\n",
       " 'face',\n",
       " 'day',\n",
       " '112102',\n",
       " 'weekend',\n",
       " 'sucked',\n",
       " 'far',\n",
       " 'jb',\n",
       " 'isnt',\n",
       " 'showing_NEG',\n",
       " 'australia_NEG',\n",
       " 'ok',\n",
       " 'thats',\n",
       " 'win',\n",
       " 'lt',\n",
       " 'way',\n",
       " 'feel',\n",
       " 'right',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'awhhe',\n",
       " 'man',\n",
       " 'im',\n",
       " 'completely',\n",
       " 'useless',\n",
       " 'rt',\n",
       " 'funny',\n",
       " 'feeling',\n",
       " 'strangely',\n",
       " 'fine',\n",
       " 'im',\n",
       " 'gonna',\n",
       " 'go',\n",
       " 'listen',\n",
       " 'semisonic',\n",
       " 'celebrate',\n",
       " 'huge',\n",
       " 'roll',\n",
       " 'thunder',\n",
       " 'nowso',\n",
       " 'scary',\n",
       " 'cut',\n",
       " 'beard',\n",
       " 'growing',\n",
       " 'well',\n",
       " 'year',\n",
       " 'im',\n",
       " 'gonna',\n",
       " 'start',\n",
       " 'shaunamanu',\n",
       " 'happy',\n",
       " 'meantime',\n",
       " 'sad',\n",
       " 'iran',\n",
       " 'wompppp',\n",
       " 'wompp',\n",
       " 'youre',\n",
       " 'one',\n",
       " 'see',\n",
       " 'cause',\n",
       " 'one_NEG',\n",
       " 'else_NEG',\n",
       " 'following_NEG',\n",
       " 'youre_NEG',\n",
       " 'pretty_NEG',\n",
       " 'awesome_NEG',\n",
       " 'ltsad',\n",
       " 'level',\n",
       " '3',\n",
       " 'writing',\n",
       " 'massive',\n",
       " 'blog',\n",
       " 'tweet',\n",
       " 'myspace',\n",
       " 'comp',\n",
       " 'shut',\n",
       " 'lost',\n",
       " 'lays',\n",
       " 'fetal',\n",
       " 'position',\n",
       " '',\n",
       " '',\n",
       " 'headed',\n",
       " 'hospitol',\n",
       " '',\n",
       " 'pull',\n",
       " 'golf',\n",
       " 'tourny',\n",
       " '3rd',\n",
       " 'place',\n",
       " 'think',\n",
       " 'reripped',\n",
       " 'something',\n",
       " '',\n",
       " 'yeah',\n",
       " '',\n",
       " 'boring',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'whats',\n",
       " 'wrong',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'please',\n",
       " 'tell',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'cant',\n",
       " 'bothered_NEG',\n",
       " 'wish_NEG',\n",
       " 'could_NEG',\n",
       " 'spend_NEG',\n",
       " 'rest_NEG',\n",
       " 'life_NEG',\n",
       " 'sat_NEG',\n",
       " 'going_NEG',\n",
       " 'gigs_NEG',\n",
       " 'seriously_NEG',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'feeeling',\n",
       " 'like',\n",
       " 'shit',\n",
       " 'right',\n",
       " 'really',\n",
       " 'want',\n",
       " 'sleep',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'goodbye',\n",
       " 'exams',\n",
       " 'didnt',\n",
       " 'realize_NEG',\n",
       " 'deep_NEG',\n",
       " 'geez_NEG',\n",
       " 'give_NEG',\n",
       " 'girl_NEG',\n",
       " 'warning_NEG',\n",
       " 'atleast_NEG',\n",
       " 'hate',\n",
       " 'athlete',\n",
       " 'appears',\n",
       " 'tear',\n",
       " 'acl',\n",
       " 'live',\n",
       " 'television',\n",
       " 'miss',\n",
       " 'guys',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'think',\n",
       " 'im',\n",
       " 'wearing',\n",
       " 'skinny',\n",
       " 'jeans',\n",
       " 'cute',\n",
       " 'sweater',\n",
       " 'heels',\n",
       " '',\n",
       " '',\n",
       " 'really_NEG',\n",
       " 'sure_NEG',\n",
       " '_NEG',\n",
       " '_NEG',\n",
       " 'today_NEG',\n",
       " '',\n",
       " 'meet',\n",
       " 'meat',\n",
       " 'httpbitly15ssci',\n",
       " 'horsie',\n",
       " 'moving',\n",
       " 'saturday',\n",
       " 'morning',\n",
       " 'sat_NEG',\n",
       " 'offneed_NEG',\n",
       " 'work_NEG',\n",
       " '6_NEG',\n",
       " 'days_NEG',\n",
       " 'week_NEG',\n",
       " 'really',\n",
       " 'dont',\n",
       " 'like_NEG',\n",
       " 'room_NEG',\n",
       " 'boring_NEG',\n",
       " '_NEG',\n",
       " 'sick_NEG',\n",
       " 'wardrobe_NEG',\n",
       " 'cant_NEG',\n",
       " 'waiit_NEG',\n",
       " 'till_NEG',\n",
       " 'walk_NEG',\n",
       " 'one_NEG',\n",
       " '_NEG',\n",
       " 'yay_NEG',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'sox',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'floyd',\n",
       " 'great',\n",
       " 'times',\n",
       " 'like',\n",
       " 'million',\n",
       " 'uploading',\n",
       " 'pictures',\n",
       " 'friendster',\n",
       " 'type',\n",
       " 'spaz',\n",
       " 'downloads',\n",
       " 'virus',\n",
       " 'brother',\n",
       " 'thats',\n",
       " '',\n",
       " 'msn',\n",
       " 'fucked',\n",
       " 'forever',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'ampampfightiin',\n",
       " 'wiit',\n",
       " 'babes',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'wrote',\n",
       " 'something',\n",
       " 'last',\n",
       " 'week',\n",
       " 'got',\n",
       " 'call',\n",
       " 'someone',\n",
       " 'new',\n",
       " 'york',\n",
       " 'office',\n",
       " 'httptumblrcomxcn21w6o7',\n",
       " 'enough',\n",
       " 'said',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'need',\n",
       " 'even',\n",
       " 'say',\n",
       " '',\n",
       " '',\n",
       " 'well',\n",
       " '',\n",
       " 'health',\n",
       " 'class',\n",
       " 'joke',\n",
       " 'ginaaa',\n",
       " 'lt3',\n",
       " 'go',\n",
       " 'show',\n",
       " 'tonight',\n",
       " 'spiralgalaxy',\n",
       " 'ymptweet',\n",
       " '',\n",
       " 'really',\n",
       " 'makes',\n",
       " 'sad',\n",
       " 'look',\n",
       " 'muslims',\n",
       " 'reality',\n",
       " '',\n",
       " 'time',\n",
       " 'low',\n",
       " 'shall',\n",
       " 'motivation',\n",
       " 'rest',\n",
       " 'week',\n",
       " '',\n",
       " '',\n",
       " 'entertainment',\n",
       " 'another',\n",
       " 'year',\n",
       " 'lakers',\n",
       " '',\n",
       " 'thats',\n",
       " 'neither',\n",
       " 'magic',\n",
       " 'fun',\n",
       " '',\n",
       " 'baddest',\n",
       " 'day',\n",
       " 'eveer',\n",
       " 'bathroom',\n",
       " 'clean',\n",
       " 'enjoyable',\n",
       " 'tasks',\n",
       " 'boom',\n",
       " 'boom',\n",
       " 'pow',\n",
       " 'im',\n",
       " 'proud',\n",
       " 'congrats',\n",
       " 'helio',\n",
       " 'though',\n",
       " 'david',\n",
       " 'must',\n",
       " 'hospitalized',\n",
       " 'five',\n",
       " 'days',\n",
       " 'end',\n",
       " 'july',\n",
       " 'palatine',\n",
       " 'tonsils',\n",
       " 'probably',\n",
       " 'never',\n",
       " 'see_NEG',\n",
       " 'katie_NEG',\n",
       " 'concert_NEG',\n",
       " 'friends',\n",
       " 'leaving',\n",
       " 'cause',\n",
       " 'stupid',\n",
       " 'love',\n",
       " '',\n",
       " 'httpbitlyzoxzc',\n",
       " 'go',\n",
       " 'give',\n",
       " 'ur',\n",
       " 'mom',\n",
       " 'hug',\n",
       " 'right',\n",
       " 'httpbitlyazfwv',\n",
       " 'going',\n",
       " 'see',\n",
       " 'harry',\n",
       " 'sunday',\n",
       " 'happiness',\n",
       " 'hand',\n",
       " 'quilting',\n",
       " 'hate',\n",
       " 'u',\n",
       " '',\n",
       " '',\n",
       " 'leysh',\n",
       " 't9ar5',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'always',\n",
       " 'get',\n",
       " 'want',\n",
       " 'bend',\n",
       " 'backwards',\n",
       " 'get',\n",
       " 'work',\n",
       " 'sooooon',\n",
       " 'miss',\n",
       " 'cody',\n",
       " 'booo',\n",
       " 'havent',\n",
       " 'seen_NEG',\n",
       " 'foreverr_NEG',\n",
       " 'hate',\n",
       " 'allergies',\n",
       " 'get',\n",
       " 'hair',\n",
       " 'cut',\n",
       " 'tomorrow',\n",
       " 'im',\n",
       " 'taking',\n",
       " 'public',\n",
       " 'poll',\n",
       " '',\n",
       " 'love',\n",
       " 'guys',\n",
       " 'much',\n",
       " 'hurts',\n",
       " 'httptumblrcomxkh1z19us',\n",
       " 'miss',\n",
       " 'earl',\n",
       " 'miss',\n",
       " 'new',\n",
       " 'jersey',\n",
       " '',\n",
       " '',\n",
       " 'missed',\n",
       " 'first',\n",
       " 'hour',\n",
       " 'sytycd',\n",
       " 'last',\n",
       " 'night',\n",
       " 'need',\n",
       " 'u2',\n",
       " 'fix',\n",
       " 'never',\n",
       " 'thought_NEG',\n",
       " 'id_NEG',\n",
       " 'become_NEG',\n",
       " 'second_NEG',\n",
       " 'choice_NEG',\n",
       " 'think',\n",
       " 'may',\n",
       " 'friendlylol',\n",
       " 'well',\n",
       " 'think',\n",
       " 'manuel',\n",
       " 'basil',\n",
       " 'plant',\n",
       " 'days',\n",
       " 'live',\n",
       " 'wanna',\n",
       " 'home',\n",
       " '',\n",
       " 'churchi',\n",
       " 'wonder',\n",
       " 'wht',\n",
       " 'wanna',\n",
       " 'make',\n",
       " 'pizza',\n",
       " '',\n",
       " '',\n",
       " 'want',\n",
       " '120gb',\n",
       " 'harddrive',\n",
       " 'want',\n",
       " 'hug',\n",
       " 'want',\n",
       " 'miley',\n",
       " 'tour',\n",
       " 'australia',\n",
       " 'wanted',\n",
       " 'sleep',\n",
       " 'morning',\n",
       " 'mean',\n",
       " 'kid',\n",
       " 'popsicle',\n",
       " 'stick',\n",
       " 'head',\n",
       " 'wish',\n",
       " 'could',\n",
       " 'fly',\n",
       " 'away',\n",
       " 'like',\n",
       " 'squirrels',\n",
       " 'slow',\n",
       " 'get',\n",
       " '1',\n",
       " 'tix',\n",
       " '',\n",
       " '',\n",
       " 'send',\n",
       " 'sunshine',\n",
       " 'northern',\n",
       " 'ireland',\n",
       " 'wish',\n",
       " 'could',\n",
       " 'go',\n",
       " 't4',\n",
       " 'beach',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'would',\n",
       " 'great',\n",
       " 'see',\n",
       " 'shontellelayne',\n",
       " 'amp',\n",
       " 'danmerriweather',\n",
       " '',\n",
       " '',\n",
       " 'would',\n",
       " 'much',\n",
       " 'happier',\n",
       " 'walls',\n",
       " 'bedroom',\n",
       " 'painted',\n",
       " 'white',\n",
       " 'idk',\n",
       " 'wat',\n",
       " '2',\n",
       " 'trust',\n",
       " 'im',\n",
       " 'sorry',\n",
       " '4',\n",
       " 'da',\n",
       " 'pain',\n",
       " 'caused',\n",
       " 'nebody',\n",
       " 'ima',\n",
       " 'take',\n",
       " 'dis',\n",
       " 'time',\n",
       " '2',\n",
       " 'straighten',\n",
       " 'luv',\n",
       " 'yall',\n",
       " 'im',\n",
       " 'finding',\n",
       " 'intercept',\n",
       " 'slopeand',\n",
       " 'banging',\n",
       " 'head',\n",
       " 'wallmath',\n",
       " 'brain',\n",
       " 'heads',\n",
       " 'come',\n",
       " 'save',\n",
       " 'im',\n",
       " 'really',\n",
       " 'going',\n",
       " 'bed',\n",
       " 'im',\n",
       " 'sick',\n",
       " '',\n",
       " 'cough',\n",
       " 'cough',\n",
       " 'cab',\n",
       " 'headed',\n",
       " 'airport',\n",
       " '',\n",
       " 'going',\n",
       " 'home',\n",
       " 'ltchristygt',\n",
       " 'case',\n",
       " 'feel',\n",
       " 'emo',\n",
       " 'camp',\n",
       " 'feeling',\n",
       " 'wee',\n",
       " 'bit',\n",
       " 'alram',\n",
       " 'bringing',\n",
       " 'human',\n",
       " 'rights',\n",
       " 'watch',\n",
       " 'world',\n",
       " 'report',\n",
       " '2009hope',\n",
       " 'itll',\n",
       " 'work',\n",
       " 'jin',\n",
       " 'twitter',\n",
       " 'jonas',\n",
       " 'day',\n",
       " 'almost',\n",
       " 'jus',\n",
       " 'got',\n",
       " 'hom',\n",
       " 'fr',\n",
       " 'tda',\n",
       " 'funeral',\n",
       " 'im',\n",
       " 'sad',\n",
       " 'cried',\n",
       " 'much',\n",
       " 'times',\n",
       " 'much',\n",
       " 'love',\n",
       " 'grandpalt3',\n",
       " 'never',\n",
       " 'got_NEG',\n",
       " 'say_NEG',\n",
       " 'last_NEG',\n",
       " 'quotgoodbyequot_NEG',\n",
       " 'gonna',\n",
       " 'smilecuz',\n",
       " 'isand',\n",
       " 'im',\n",
       " 'sure_NEG',\n",
       " 'could_NEG',\n",
       " 'want_NEG',\n",
       " '',\n",
       " '',\n",
       " 'got',\n",
       " 'home',\n",
       " '',\n",
       " 'longest',\n",
       " 'night',\n",
       " 'ever',\n",
       " 'ugh',\n",
       " 'httptumblrcomxwp1yxhi6',\n",
       " 'mi',\n",
       " 'momacita',\n",
       " 'wont',\n",
       " 'let_NEG',\n",
       " 'go_NEG',\n",
       " 'bfs_NEG',\n",
       " 'bball_NEG',\n",
       " 'game_NEG',\n",
       " 'grrr_NEG',\n",
       " 'mom',\n",
       " 'says',\n",
       " 'get',\n",
       " 'new',\n",
       " 'phone',\n",
       " 'immediatelyoff',\n",
       " 'tmobile',\n",
       " '',\n",
       " 'paying',\n",
       " 'new',\n",
       " 'car',\n",
       " 'stolenby',\n",
       " 'mother',\n",
       " 'wanted',\n",
       " 'go',\n",
       " 'pose',\n",
       " 'church',\n",
       " '',\n",
       " '',\n",
       " 'hang_NEG',\n",
       " 'girls_NEG',\n",
       " '2day_NEG',\n",
       " '2moro_NEG',\n",
       " 'movie_NEG',\n",
       " 'times_NEG',\n",
       " 'sunday_NEG',\n",
       " '_NEG',\n",
       " 'rats_NEG',\n",
       " 'plan_NEG',\n",
       " 'tomorrow_NEG',\n",
       " 'guess_NEG',\n",
       " 'means_NEG',\n",
       " 'work_NEG',\n",
       " 'two_NEG',\n",
       " '_NEG',\n",
       " 'presentations_NEG',\n",
       " 'pavel_NEG',\n",
       " 'tonight_NEG',\n",
       " 'lttigersfan_NEG',\n",
       " 'gt_NEG',\n",
       " 'cool_NEG',\n",
       " 'night_NEG',\n",
       " 'oh',\n",
       " 'thank',\n",
       " 'pleased',\n",
       " 'probably',\n",
       " 'guna',\n",
       " 'get',\n",
       " 'soon',\n",
       " 'since',\n",
       " 'one_NEG',\n",
       " 'talkin_NEG',\n",
       " 'really',\n",
       " 'wanted',\n",
       " 'safina',\n",
       " 'pull',\n",
       " 'win',\n",
       " 'amp',\n",
       " 'lose',\n",
       " 'like',\n",
       " '',\n",
       " '',\n",
       " 'rip',\n",
       " 'rose',\n",
       " 'ood',\n",
       " 'back',\n",
       " 'xmas',\n",
       " 'special',\n",
       " '',\n",
       " 'yay',\n",
       " '',\n",
       " 'damn',\n",
       " 'thats',\n",
       " 'half',\n",
       " 'year',\n",
       " 'away',\n",
       " '',\n",
       " 'sannesias',\n",
       " 'aww',\n",
       " 'neighbor_NEG',\n",
       " 'need_NEG',\n",
       " 'watch_NEG',\n",
       " 'mean_NEG',\n",
       " 'girls_NEG',\n",
       " '_NEG',\n",
       " 'httptumblrcomxv31s2pi8_NEG',\n",
       " 'whats',\n",
       " 'status',\n",
       " 'next',\n",
       " 'weekend',\n",
       " 'sorry',\n",
       " 'gigi4462',\n",
       " 'ex',\n",
       " 'husband',\n",
       " 'overdosed',\n",
       " 'daily',\n",
       " 'dose',\n",
       " 'haterade',\n",
       " 'thanks',\n",
       " 'definition',\n",
       " 'throwbie',\n",
       " '',\n",
       " 'editors',\n",
       " 'reviewed',\n",
       " 'entry',\n",
       " 'decided',\n",
       " 'publish_NEG',\n",
       " '',\n",
       " '',\n",
       " 'thanks',\n",
       " '',\n",
       " 'explains',\n",
       " 'alot',\n",
       " 'theres',\n",
       " 'going',\n",
       " 'heathers',\n",
       " 'sequel',\n",
       " '',\n",
       " 'winona4ever',\n",
       " '',\n",
       " 'better',\n",
       " 'fuck_NEG',\n",
       " '',\n",
       " '',\n",
       " 'told',\n",
       " 'drink_NEG',\n",
       " 'wmy_NEG',\n",
       " 'rx_NEG',\n",
       " 'gave_NEG',\n",
       " 'bb_NEG',\n",
       " 'porter_NEG',\n",
       " 'amp_NEG',\n",
       " 'obs_NEG',\n",
       " 'stout_NEG',\n",
       " 'brought_NEG',\n",
       " 'home_NEG',\n",
       " 'neighbors_NEG',\n",
       " '_NEG',\n",
       " 'v_NEG',\n",
       " 'trae',\n",
       " 'sweet',\n",
       " 'bought',\n",
       " 'new',\n",
       " 'baithing',\n",
       " 'suit',\n",
       " 'wove',\n",
       " '',\n",
       " '',\n",
       " 'true',\n",
       " 'u',\n",
       " 'guys',\n",
       " 'knw',\n",
       " 'whyy',\n",
       " 'much',\n",
       " 'waahhh',\n",
       " 'im',\n",
       " 'getting',\n",
       " 'sadmiss',\n",
       " 'hub',\n",
       " 'quotquotquotquotquotquotquotquot',\n",
       " '',\n",
       " '',\n",
       " 'standing',\n",
       " 'pouring',\n",
       " 'rain',\n",
       " 'sitting',\n",
       " 'top',\n",
       " 'world',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'summer',\n",
       " 'sucks',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'went',\n",
       " 'get',\n",
       " 'dog',\n",
       " 'vets',\n",
       " 'picture',\n",
       " 'feel',\n",
       " 'naked',\n",
       " 'arent',\n",
       " 'trains_NEG',\n",
       " 'going_NEG',\n",
       " 'manchester_NEG',\n",
       " 'sunday_NEG',\n",
       " '_NEG',\n",
       " 'cant_NEG',\n",
       " 'go_NEG',\n",
       " 'jonasbrothers_NEG',\n",
       " 'concert_NEG',\n",
       " '',\n",
       " 'must',\n",
       " 'people',\n",
       " 'picky',\n",
       " 'mean',\n",
       " '6',\n",
       " 'hours',\n",
       " 'work',\n",
       " 'dice_NEG',\n",
       " 'whatï¿½s_NEG',\n",
       " 'httptumblrcomxsg1m3ufn_NEG',\n",
       " 'twitter',\n",
       " 'soon',\n",
       " 'become',\n",
       " 'obsolete',\n",
       " 'httpwwwimediaconnectioncomcontent23465asp',\n",
       " 'wide',\n",
       " 'awake',\n",
       " '',\n",
       " '',\n",
       " 'yeah',\n",
       " 'awful',\n",
       " 'weather',\n",
       " 'last',\n",
       " 'week',\n",
       " 'stinks',\n",
       " 'kristis',\n",
       " 'comin',\n",
       " 'moe',\n",
       " 'said',\n",
       " 'mmmaybe',\n",
       " 'take',\n",
       " 'us',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'hi',\n",
       " 'stranger',\n",
       " 'hello',\n",
       " 'frank',\n",
       " 'lampard',\n",
       " 'fine',\n",
       " 'urself',\n",
       " 'stranger',\n",
       " 'gay',\n",
       " 'httptumblrcomxaj24dkly',\n",
       " 'youll',\n",
       " 'always',\n",
       " 'one',\n",
       " '',\n",
       " '12232007',\n",
       " '3turnoffwords',\n",
       " 'shit',\n",
       " 'sucks',\n",
       " 'asylm',\n",
       " 'j2',\n",
       " 'panel',\n",
       " 'guess',\n",
       " 'back',\n",
       " 'normal',\n",
       " 'life',\n",
       " 'poemsunder140',\n",
       " 'started',\n",
       " 'shannonelyse1',\n",
       " 'squarespace',\n",
       " 'brighten',\n",
       " 'bad',\n",
       " 'day',\n",
       " 'never',\n",
       " 'win_NEG',\n",
       " 'anything_NEG',\n",
       " '',\n",
       " 'susan',\n",
       " 'boyle',\n",
       " 'didnt',\n",
       " 'win_NEG',\n",
       " 'mh_NEG',\n",
       " 'well_NEG',\n",
       " 'twenty20',\n",
       " '',\n",
       " 'lt',\n",
       " 'lt3',\n",
       " 'goooood',\n",
       " 'timessss',\n",
       " 'lt3',\n",
       " 'graduate',\n",
       " '09lt3',\n",
       " '',\n",
       " 'quot',\n",
       " 'vandals',\n",
       " 'paint',\n",
       " 'swastikas',\n",
       " 'home',\n",
       " 'author',\n",
       " 'gay',\n",
       " 'quotan',\n",
       " 'unknown',\n",
       " 'error',\n",
       " 'occured',\n",
       " '4quot',\n",
       " 'uh',\n",
       " 'oh',\n",
       " 'iphone',\n",
       " 'os',\n",
       " '3',\n",
       " 'fail',\n",
       " 'far',\n",
       " 'quotexperts',\n",
       " 'homers',\n",
       " 'predict',\n",
       " 'eagles',\n",
       " 'go',\n",
       " '124',\n",
       " 'giants',\n",
       " 'go',\n",
       " '97',\n",
       " 'bs',\n",
       " 'httpwwwdailysportspagescomforumsshowthreadphpt49343',\n",
       " 'quoti',\n",
       " 'know',\n",
       " 'hungry',\n",
       " ...]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words_neg_nostops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria um unigram (n-grama) e extrai as features\n",
    "unigram_feats = sentiment_analyzer.unigram_word_feats(all_words_neg_nostops, top_n = 200)\n",
    "sentiment_analyzer.add_feat_extractor(extract_unigram_feats, unigrams = unigram_feats)\n",
    "training_set = sentiment_analyzer.apply_features(dataset_treino_amostra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.collections.LazyMap"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({'contains()': False, 'contains(im)': False, 'contains(_NEG)': False, 'contains(followfriday)': False, 'contains(amp)': False, 'contains(dont)': False, 'contains(day)': False, 'contains(love)': False, 'contains(like)': False, 'contains(cant)': False, 'contains(good)': False, 'contains(get)': False, 'contains(go)': False, 'contains(today)': False, 'contains(got)': False, 'contains(want)': False, 'contains(time)': False, 'contains(going)': False, 'contains(back)': False, 'contains(one)': False, 'contains(sad)': True, 'contains(really)': False, 'contains(miss)': False, 'contains(u)': False, 'contains(work)': False, 'contains(new)': False, 'contains(2)': False, 'contains(last)': False, 'contains(still)': False, 'contains(twitter)': False, 'contains(night)': False, 'contains(great)': False, 'contains(lol)': False, 'contains(follow)': False, 'contains(need)': False, 'contains(see)': False, 'contains(much)': False, 'contains(myweakness)': False, 'contains(get_NEG)': False, 'contains(didnt)': False, 'contains(think)': False, 'contains(hate)': False, 'contains(iremember)': False, 'contains(home)': False, 'contains(feel)': False, 'contains(musicmonday)': False, 'contains(know)': False, 'contains(happy)': False, 'contains(people)': False, 'contains(lt3)': False, 'contains(would)': False, 'contains(bad)': False, 'contains(well)': False, 'contains(right)': False, 'contains(wish)': False, 'contains(oh)': False, 'contains(gonna)': False, 'contains(tomorrow)': False, 'contains(tonight)': False, 'contains(ff)': False, 'contains(ill)': False, 'contains(please)': False, 'contains(hope)': False, 'contains(thanks)': False, 'contains(morning)': False, 'contains(someone)': False, 'contains(never)': False, 'contains(ive)': False, 'contains(make)': False, 'contains(getting)': False, 'contains(im_NEG)': False, 'contains(go_NEG)': False, 'contains(know_NEG)': False, 'contains(awesome)': False, 'contains(like_NEG)': False, 'contains(inaperfectworld)': False, 'contains(thats)': False, 'contains(come)': False, 'contains(squarespace)': False, 'contains(wont)': False, 'contains(haha)': False, 'contains(lt)': False, 'contains(wanna)': False, 'contains(1)': False, 'contains(lost)': False, 'contains(days)': False, 'contains(4)': False, 'contains(makes)': False, 'contains(fun)': False, 'contains(friends)': False, 'contains(life)': False, 'contains(best)': False, 'contains(iphone)': False, 'contains(quoti)': False, 'contains(good_NEG)': False, 'contains(could)': False, 'contains(song)': False, 'contains(school)': False, 'contains(bed)': False, 'contains(better)': False, 'contains(dontyouhate)': False, 'contains(first)': False, 'contains(ever)': False, 'contains(3)': False, 'contains(us)': False, 'contains(haveyouever)': False, 'contains(sick)': False, 'contains(nice)': False, 'contains(man)': False, 'contains(want_NEG)': False, 'contains(doesnt)': False, 'contains(everyone)': False, 'contains(already)': False, 'contains(one_NEG)': False, 'contains(guys)': False, 'contains(show)': False, 'contains(sorry)': False, 'contains(week)': False, 'contains(music)': False, 'contains(things)': False, 'contains(old)': False, 'contains(bgt)': False, 'contains(next)': False, 'contains(made)': False, 'contains(something)': False, 'contains(n)': False, 'contains(way)': False, 'contains(another)': False, 'contains(gt)': False, 'contains(sleep)': False, 'contains(take)': False, 'contains(soon)': False, 'contains(baby)': False, 'contains(isnt)': False, 'contains(work_NEG)': False, 'contains(little)': False, 'contains(away)': False, 'contains(damn)': False, 'contains(quot)': False, 'contains(say)': False, 'contains(always)': False, 'contains(phone)': False, 'contains(left)': False, 'contains(shes)': False, 'contains(see_NEG)': False, 'contains(summer)': False, 'contains(weekend)': False, 'contains(year)': False, 'contains(today_NEG)': False, 'contains(amazing)': False, 'contains(wait_NEG)': False, 'contains(ok)': False, 'contains(long)': False, 'contains(girl)': False, 'contains(world)': False, 'contains(watching)': False, 'contains(movie)': False, 'contains(goodsex)': False, 'contains(feeling)': False, 'contains(ur)': False, 'contains(watch)': False, 'contains(cool)': False, 'contains(found)': False, 'contains(friend)': True, 'contains(mom)': False, 'contains(hes)': False, 'contains(friday)': False, 'contains(done)': False, 'contains(hours)': False, 'contains(said)': False, 'contains(went)': False, 'contains(gone)': False, 'contains(tired)': False, 'contains(house)': False, 'contains(missed)': False, 'contains(give)': False, 'contains(rain)': False, 'contains(leave)': False, 'contains(thing)': False, 'contains(wanted)': False, 'contains(head)': False, 'contains(sucks)': False, 'contains(sleep_NEG)': False, 'contains(ready)': False, 'contains(thank)': False, 'contains(guess)': False, 'contains(nothing)': False, 'contains(talk)': False, 'contains(followers)': False, 'contains(keep)': False, 'contains(tweets)': False, 'contains(look)': False, 'contains(hurts)': False, 'contains(early)': False, 'contains(game)': False, 'contains(two)': False, 'contains(guy)': False, 'contains(cry)': False, 'contains(going_NEG)': False, 'contains(live)': False}, '0'), ({'contains()': False, 'contains(im)': False, 'contains(_NEG)': False, 'contains(followfriday)': False, 'contains(amp)': False, 'contains(dont)': False, 'contains(day)': False, 'contains(love)': False, 'contains(like)': False, 'contains(cant)': False, 'contains(good)': False, 'contains(get)': False, 'contains(go)': False, 'contains(today)': False, 'contains(got)': False, 'contains(want)': False, 'contains(time)': False, 'contains(going)': False, 'contains(back)': False, 'contains(one)': False, 'contains(sad)': False, 'contains(really)': False, 'contains(miss)': False, 'contains(u)': False, 'contains(work)': False, 'contains(new)': True, 'contains(2)': False, 'contains(last)': False, 'contains(still)': False, 'contains(twitter)': False, 'contains(night)': False, 'contains(great)': False, 'contains(lol)': False, 'contains(follow)': False, 'contains(need)': False, 'contains(see)': False, 'contains(much)': False, 'contains(myweakness)': False, 'contains(get_NEG)': False, 'contains(didnt)': False, 'contains(think)': False, 'contains(hate)': False, 'contains(iremember)': False, 'contains(home)': False, 'contains(feel)': False, 'contains(musicmonday)': False, 'contains(know)': False, 'contains(happy)': False, 'contains(people)': False, 'contains(lt3)': False, 'contains(would)': False, 'contains(bad)': False, 'contains(well)': False, 'contains(right)': False, 'contains(wish)': False, 'contains(oh)': False, 'contains(gonna)': False, 'contains(tomorrow)': False, 'contains(tonight)': False, 'contains(ff)': False, 'contains(ill)': False, 'contains(please)': False, 'contains(hope)': False, 'contains(thanks)': False, 'contains(morning)': False, 'contains(someone)': False, 'contains(never)': False, 'contains(ive)': False, 'contains(make)': False, 'contains(getting)': False, 'contains(im_NEG)': False, 'contains(go_NEG)': False, 'contains(know_NEG)': False, 'contains(awesome)': False, 'contains(like_NEG)': False, 'contains(inaperfectworld)': False, 'contains(thats)': False, 'contains(come)': False, 'contains(squarespace)': False, 'contains(wont)': False, 'contains(haha)': False, 'contains(lt)': False, 'contains(wanna)': False, 'contains(1)': False, 'contains(lost)': False, 'contains(days)': False, 'contains(4)': False, 'contains(makes)': False, 'contains(fun)': False, 'contains(friends)': False, 'contains(life)': False, 'contains(best)': False, 'contains(iphone)': False, 'contains(quoti)': False, 'contains(good_NEG)': False, 'contains(could)': False, 'contains(song)': False, 'contains(school)': False, 'contains(bed)': False, 'contains(better)': False, 'contains(dontyouhate)': False, 'contains(first)': False, 'contains(ever)': False, 'contains(3)': False, 'contains(us)': False, 'contains(haveyouever)': False, 'contains(sick)': False, 'contains(nice)': False, 'contains(man)': False, 'contains(want_NEG)': False, 'contains(doesnt)': False, 'contains(everyone)': False, 'contains(already)': False, 'contains(one_NEG)': False, 'contains(guys)': False, 'contains(show)': False, 'contains(sorry)': False, 'contains(week)': False, 'contains(music)': False, 'contains(things)': False, 'contains(old)': False, 'contains(bgt)': False, 'contains(next)': False, 'contains(made)': False, 'contains(something)': False, 'contains(n)': False, 'contains(way)': False, 'contains(another)': False, 'contains(gt)': False, 'contains(sleep)': False, 'contains(take)': False, 'contains(soon)': False, 'contains(baby)': False, 'contains(isnt)': False, 'contains(work_NEG)': False, 'contains(little)': False, 'contains(away)': False, 'contains(damn)': False, 'contains(quot)': False, 'contains(say)': False, 'contains(always)': False, 'contains(phone)': False, 'contains(left)': False, 'contains(shes)': False, 'contains(see_NEG)': False, 'contains(summer)': False, 'contains(weekend)': False, 'contains(year)': False, 'contains(today_NEG)': False, 'contains(amazing)': False, 'contains(wait_NEG)': False, 'contains(ok)': False, 'contains(long)': False, 'contains(girl)': False, 'contains(world)': False, 'contains(watching)': False, 'contains(movie)': False, 'contains(goodsex)': False, 'contains(feeling)': False, 'contains(ur)': False, 'contains(watch)': False, 'contains(cool)': False, 'contains(found)': False, 'contains(friend)': False, 'contains(mom)': False, 'contains(hes)': False, 'contains(friday)': False, 'contains(done)': False, 'contains(hours)': False, 'contains(said)': False, 'contains(went)': False, 'contains(gone)': False, 'contains(tired)': False, 'contains(house)': False, 'contains(missed)': True, 'contains(give)': False, 'contains(rain)': False, 'contains(leave)': False, 'contains(thing)': False, 'contains(wanted)': False, 'contains(head)': False, 'contains(sucks)': False, 'contains(sleep_NEG)': False, 'contains(ready)': False, 'contains(thank)': False, 'contains(guess)': False, 'contains(nothing)': False, 'contains(talk)': False, 'contains(followers)': False, 'contains(keep)': False, 'contains(tweets)': False, 'contains(look)': False, 'contains(hurts)': False, 'contains(early)': False, 'contains(game)': False, 'contains(two)': False, 'contains(guy)': False, 'contains(cry)': False, 'contains(going_NEG)': False, 'contains(live)': False}, '0'), ...]\n"
     ]
    }
   ],
   "source": [
    "print(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier\n"
     ]
    }
   ],
   "source": [
    "# Treinar o modelo\n",
    "trainer = NaiveBayesClassifier.train\n",
    "classifier = sentiment_analyzer.train(trainer, training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testa o classificador em algumas sentenças\n",
    "test_sentence1 = [(['this', 'program', 'is', 'bad'], '')]\n",
    "test_sentence2 = [(['tough', 'day', 'at', 'work', 'today'], '')]\n",
    "test_sentence3 = [(['good', 'wonderful', 'amazing', 'awesome'], '')]\n",
    "test_set = sentiment_analyzer.apply_features(test_sentence1)\n",
    "test_set2 = sentiment_analyzer.apply_features(test_sentence2)\n",
    "test_set3 = sentiment_analyzer.apply_features(test_sentence3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Com o Classificador pronto vamos preparar a conexão com o Twitter para aplicar esse classificador em tempo real "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autenticação do Twitter com os dados da nossa conta de desenvolvedor \n",
    "consumer_key = \"xxx\"\n",
    "consumer_secret = \"xxx\"\n",
    "access_token = \"xxx\"\n",
    "access_token_secret = \"xxx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Especifica a URL termo de busca\n",
    "#Vamos buscar dados sobre o trump\n",
    "search_term = 'Bolsonaro'\n",
    "#Vamos buscar no próprio streaming do twitter \n",
    "sample_url = 'https://stream.twitter.com/1.1/statuses/sample.json'\n",
    "#Filtrando os termos que tem a palavra trump\n",
    "filter_url = 'https://stream.twitter.com/1.1/statuses/filter.json?track='+search_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o objeto de atutenticação para o Twitter\n",
    "auth = requests_oauthlib.OAuth1(consumer_key, consumer_secret, access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurando o Stream\n",
    "#Criando um RDD vazio\n",
    "rdd = ssc.sparkContext.parallelize([0])\n",
    "# Os dados vão chegando em tempo real assim precisamos criar a seguinte fila de RDDs para receber os dados \n",
    "stream = ssc.queueStream([], default = rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.streaming.dstream.DStream"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total de tweets por update\n",
    "NUM_TWEETS = 500  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essa função conecta ao Twitter e retorna um número específico de Tweets (NUM_TWEETS)\n",
    "def tfunc(t, rdd):\n",
    "  return rdd.flatMap(lambda x: stream_twitter_data())\n",
    "\n",
    "#Função que conecta notwitter e passa o filtro do Trump que estabelecemos \n",
    "def stream_twitter_data():\n",
    "  response = requests.get(filter_url, auth = auth, stream = True)\n",
    "  print(filter_url, response)\n",
    "  count = 0\n",
    "  for line in response.iter_lines():\n",
    "    try:\n",
    "      if count > NUM_TWEETS:\n",
    "        break\n",
    "      post = json.loads(line.decode('utf-8'))\n",
    "      contents = [post['text']]\n",
    "      count += 1\n",
    "      yield str(contents)\n",
    "    except:\n",
    "      result = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = stream.transform(tfunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retornando caa twitter da mesma forma que estamos coletando ou seja na forma literal \n",
    "coord_stream = stream.map(lambda line: ast.literal_eval(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essa função classifica os tweets, aplicando as features do modelo criado anteriormente\n",
    "def classifica_tweet(tweet):\n",
    "  sentence = [(tweet, '')]\n",
    "  test_set = sentiment_analyzer.apply_features(sentence)\n",
    "  print(tweet, classifier.classify(test_set[0][0]))\n",
    "  return(tweet, classifier.classify(test_set[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essa função retorna o texto do Twitter\n",
    "def get_tweet_text(rdd):\n",
    "  for line in rdd:\n",
    "    tweet = line.strip()\n",
    "    translator = str.maketrans({key: None for key in string.punctuation})\n",
    "    tweet = tweet.translate(translator)\n",
    "    tweet = tweet.split(' ')\n",
    "    tweet_lower = []\n",
    "    for word in tweet:\n",
    "      tweet_lower.append(word.lower())\n",
    "    return(classifica_tweet(tweet_lower))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma lista vazia para os resultados\n",
    "resultados = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essa função salva o resultado dos batches de Tweets junto com o timestamp\n",
    "def output_rdd(rdd):\n",
    "  global resultados\n",
    "  pairs = rdd.map(lambda x: (get_tweet_text(x)[1],1))\n",
    "  counts = pairs.reduceByKey(add)\n",
    "  output = []\n",
    "  for count in counts.collect():\n",
    "    output.append(count)\n",
    "  result = [time.strftime(\"%I:%M:%S\"), output]\n",
    "  resultados.append(result)\n",
    "  print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A função foreachRDD() aplica uma função a cada RDD to streaming de dados\n",
    "coord_stream.foreachRDD(lambda t, rdd: output_rdd(rdd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start streaming\n",
    "ssc.start()\n",
    "# ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['04:18:28', []]\n",
      "['04:18:33', []]\n",
      "['04:18:37', []]\n",
      "['04:18:42', []]\n",
      "['04:18:47', []]\n",
      "['04:18:52', []]\n"
     ]
    }
   ],
   "source": [
    "cont = True\n",
    "while cont:\n",
    "  if len(resultados) > 5:\n",
    "    cont = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grava os resultados\n",
    "rdd_save = ''+time.strftime(\"%I%M%S\")\n",
    "resultados_rdd = sc.parallelize(resultados)\n",
    "resultados_rdd.saveAsTextFile(rdd_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['04:18:28', []],\n",
       " ['04:18:33', []],\n",
       " ['04:18:37', []],\n",
       " ['04:18:42', []],\n",
       " ['04:18:47', []],\n",
       " ['04:18:52', []]]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualiza os resultados\n",
    "resultados_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finaliza o streaming\n",
    "ssc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obrigado - Data Science Academy - <a href=\"http://facebook.com/dsacademybr\">facebook.com/dsacademybr</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
